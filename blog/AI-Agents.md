# AI Agents

This blog post is to outline my experience working with and deploying AI agents, from the beginning of my experience until the present time.

## Table of Contents
1. [Thoughts on AI/AI Agents in general](#thoughts-on-aiai-agents-in-general)
2. [Where I started](#where-i-started)
3. [Transition to OpenClaw](#version-four-transition-to-openclaw)
4. [Future work](#future-work)

# Thoughts on AI/AI Agents in general
How I feel about AI in general: It's a tool. Like every tool, one needs to use it properly. Also like every tool, one needs to get to the point where they aren't relying on it. If you use it improperly, it's going to kill your skills of reasoning and thinking. A person should not be afraid to have the AI challenge them on things. One should not be afraid to expand their point of view; but also, stick to what they believe in, and not let a language model lead them towards views they don't believe are morally or ethically right. 

I believe AI is the next great equalizer in assistive technology. AI can simplify or structure language in more accessible ways and allow text-to-speech and speech-to-text to be enabled at a greater and more natural capacity, among many other things that I'm excited to see in the near and far future. Personally, AI is my sounding board and a part of my capacity management system. It allows me to do things I love and know the costs so that recovery is possible and more efficient. Yes, I do rely on an LLM every day (!) to devise what I'm doing for the day, but I can still reconstruct that same information later. I know exactly what's going into the LLM as inputs and what's coming out as outputs. I use AI to make many things easier on myself, that I can do myself, but choose not to because of the immense emotional or cognitive load that those tasks possess.

# Where I started
The previous structure of my 'AI' Agentic system was a single-agent, nondeterministic system. It brought *some* structure to my life, but not enough. As a start, it worked as a great system, helping me to reduce decision fatigue by integrating my calendar data (which included academic deadlines and personal commitments) into structured daily plans. However, the system only structured *what I have on my schedule*, not necessarily *how* to get started on a task. Nor did it accurately estimate the amount of energy that a task would take, which led me to devise a system to track this concept.

Overall, I continued to iterate this system, including the Work Unit system[^1], to create a version two of the agent. Did it become over-engineered? Absolutely. There were over twelve Apple Shortcuts, eight with a LLM call involved. I realized that the system in that state was also not as deterministic as I needed it to be, and I then set on a journey to create a better version of the system. I completely rehauled the system to use more code for its preprocessing and only one 'agent' again in the end to provide consistent output to me in the form of a daily briefing email. The crux of the problem after this current optimization is that I can't track Work Unit expenditure over time; I just have to rely on knowing the values of Work Units for completing activities that are on my calendar. Tracking Work Unit expenditure for completing assignments and non-calendar-based tasks, such as responding to emails or working on projects outside of the classroom, is also impossible under the current regime. Version 3 is 'good enough,' and refines the overengineering aspect to become more 'engineered' and less 'over-the-top', but it isn't 'perfect.'

Keeping my personal data local, especially as the telemetry pipeline becomes greater, was also on my mind as I worked on the code-based portion of the project. Thus, another solution had to be born, and I started my research into other agentic systems. Using [Ollama](https://ollama.com/), a local LLM service, seemed to be the right fit for my use case. However, Apple Shortcuts and Ollama do not mix, especially if the computer running the shortcut is asleep overnight. Using an API call to an external model, such as GPT-5.2, was the only way to reliably get output at 04:00 every day.

# Version Four: Transition to OpenClaw
[This is also a full blog post](Transition-to-OpenClaw.md), particularly about the setup process and how I have set up the workflow. However, I do want to go into some general amount of detail about *why* I chose to migrate to OpenClaw for my personal system. 

OpenClaw has **native local provider support** as long as the 'API' in question supports either OpenAI or Anthropic specs, specifically including [documentation on how to use Ollama](https://docs.openclaw.ai/providers/ollama) with its documentation on how to access other providers. I already have used and experimented with Ollama in the past, which made me inclined to use it as my model provider for OpenClaw. OpenClaw is also **open source**, so I don't have to worry about a company taking my data (highly likely, look at the Discord ID verification data breach), or simply refusing to provide the product anymore if they find it unprofitable (highly unlikely). I can simply copy the repository and run it locally without any connection to the internet for sensitive information. I also wanted to experiment with using skills and tools with frontier LLMs, and OpenClaw conforms to the [AgentSkills spec](https://agentskills.io/home), which gives me a lot of references to build off of for custom skills. 

# Future work
After migrating to OpenClaw, I hope that I'll have an idea of where I want to take my agent system next. The current pipeline is here to stay, especially because it is telemetry that will feed future agents' work and tasks. Before the full migration to OpenClaw, however, I will be iterating on the telemetry system that currently feeds the planning 'agent' that I have. Particularly, I want to add work unit calculation to Canvas assignment completion, and add a system to feed side projects (like this blog) into the daily plan and Work Unit calculations. This data will be critical for the OpenClaw 'fleet', so to speak, so getting it done now before implementing the agents I have plans for is priority number one.

# Footnotes
[^1]: In essence, the Work Unit system is a further, more structured expansion on the disability concepts of ["spoon theory"](https://web.archive.org/web/20191117210039/https://butyoudontlooksick.com/articles/written-by-christine/the-spoon-theory/) and ["battery analogy"](https://batemanhornecenter.org/wp-content/uploads/2024/10/Video-Transcript-Life-with-a-Low-Battery-Living-with-MECFS.pdf) while incorporating parts that I thought were missing from these analogies for my personal theory of energy and capacity. For a further explanation of how the system works, I encourage you to read [my blog post on the topic](Work-Units.md).